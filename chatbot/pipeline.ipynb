{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c47df9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ee1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_google_genai\n",
      "  Using cached langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain_google_genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.49 (from langchain_google_genai)\n",
      "  Using cached langchain_core-0.3.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting pydantic<3,>=2 (from langchain_google_genai)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (5.29.3)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached langsmith-0.3.30-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.49->langchain_google_genai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.49->langchain_google_genai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.49->langchain_google_genai) (4.12.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2->langchain_google_genai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=2->langchain_google_genai)\n",
      "  Using cached pydantic_core-2.33.1-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=2->langchain_google_genai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached googleapis_common_protos-1.69.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (1.70.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached grpcio_status-1.72.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached orjson-3.10.16-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached grpcio-1.72.0rc1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai) (3.10)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain_google_genai) (2.3.0)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.49->langchain_google_genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain_google_genai-2.1.2-py3-none-any.whl (42 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
      "Using cached langchain_core-0.3.51-py3-none-any.whl (423 kB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Using cached pydantic_core-2.33.1-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
      "Using cached google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.3.30-py3-none-any.whl (358 kB)\n",
      "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached googleapis_common_protos-1.69.2-py3-none-any.whl (293 kB)\n",
      "Downloading grpcio_status-1.72.0rc1-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Using cached grpcio-1.72.0rc1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.16-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: filetype, zstandard, typing-inspection, tenacity, sniffio, pydantic-core, pyasn1, protobuf, orjson, jsonpointer, h11, grpcio, cachetools, annotated-types, rsa, requests-toolbelt, pydantic, pyasn1-modules, proto-plus, jsonpatch, httpcore, googleapis-common-protos, anyio, httpx, grpcio-status, google-auth, langsmith, google-api-core, langchain-core, google-ai-generativelanguage, langchain_google_genai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.70.0\n",
      "    Uninstalling grpcio-1.70.0:\n",
      "      Successfully uninstalled grpcio-1.70.0\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 cachetools-5.5.2 filetype-1.2.0 google-ai-generativelanguage-0.6.17 google-api-core-2.24.2 google-auth-2.38.0 googleapis-common-protos-1.69.2 grpcio-1.72.0rc1 grpcio-status-1.72.0rc1 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.51 langchain_google_genai-2.1.2 langsmith-0.3.30 orjson-3.10.16 proto-plus-1.26.1 protobuf-6.30.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.3 pydantic-core-2.33.1 requests-toolbelt-1.0.0 rsa-4.9 sniffio-1.3.1 tenacity-9.1.2 typing-inspection-0.4.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.30.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_community) (0.3.51)\n",
      "Collecting langchain<1.0.0,>=0.3.23 (from langchain_community)\n",
      "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Using cached sqlalchemy-2.0.40-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Using cached aiohttp-3.11.16-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_community) (0.3.30)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_community) (2.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached yarl-1.19.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain_community)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain_community) (2.11.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain_community) (0.4.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
      "Using cached langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.11.16-cp312-cp312-win_amd64.whl (438 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "Using cached pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Using cached sqlalchemy-2.0.40-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.19.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, propcache, mypy-extensions, multidict, marshmallow, httpx-sse, greenlet, frozenlist, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.40 aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 httpx-sse-0.4.0 langchain-0.3.23 langchain-text-splitters-0.3.8 langchain_community-0.3.21 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.0.0 propcache-0.3.1 pydantic-settings-2.8.1 python-dotenv-1.1.0 typing-inspect-0.9.0 yarl-1.19.0\n",
      "Collecting langchain_huggingface\n",
      "  Using cached langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from langchain_huggingface)\n",
      "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain_huggingface) (0.3.51)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n",
      "  Using cached sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain_huggingface)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain_huggingface)\n",
      "  Using cached transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.23.0->langchain_huggingface)\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.23.0->langchain_huggingface)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.3.30)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.11.3)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n",
      "Collecting Pillow (from sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (2.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.39.0->langchain_huggingface)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.39.0->langchain_huggingface)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2025.1.31)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (75.8.2)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain_huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
      "Using cached langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
      "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Using cached sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, tqdm, sympy, safetensors, regex, Pillow, networkx, jinja2, fsspec, torch, huggingface-hub, tokenizers, transformers, sentence-transformers, langchain_huggingface\n",
      "Successfully installed Pillow-11.2.1 fsspec-2025.3.2 huggingface-hub-0.30.2 jinja2-3.1.6 langchain_huggingface-0.1.2 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 safetensors-0.5.3 sentence-transformers-4.0.2 sympy-1.13.1 tokenizers-0.21.1 torch-2.6.0 tqdm-4.67.1 transformers-4.51.2\n",
      "Collecting gradio\n",
      "  Using cached gradio-5.25.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Using cached gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (2.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: packaging in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (11.2.1)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (2.11.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Using cached ruff-0.11.5-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Using cached uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Using cached gradio-5.25.0-py3-none-any.whl (46.9 MB)\n",
      "Using cached gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Using cached ruff-0.11.5-py3-none-win_amd64.whl (11.4 MB)\n",
      "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
      "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached websockets-15.0.1-cp312-cp312-win_amd64.whl (176 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, groovy, ffmpy, click, aiofiles, uvicorn, starlette, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "Successfully installed aiofiles-24.1.0 click-8.1.8 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.0 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.5 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.2 tomlkit-0.13.2 typer-0.15.2 uvicorn-0.34.1 websockets-15.0.1\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Using cached rapidfuzz-3.13.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: rapidfuzz\n",
      "Successfully installed rapidfuzz-3.13.0\n",
      "Collecting pypdf\n",
      "  Using cached pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Using cached pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.4.0\n",
      "Collecting faiss-cpu\n",
      "  Using cached faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Using cached faiss_cpu-1.10.0-cp312-cp312-win_amd64.whl (13.7 MB)\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.8.5-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Using cached murmurhash-1.0.12-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Using cached cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Using cached thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Using cached srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (75.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Using cached spacy-3.8.5-cp312-cp312-win_amd64.whl (11.8 MB)\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Using cached cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Using cached murmurhash-1.0.12-cp312-cp312-win_amd64.whl (25 kB)\n",
      "Using cached preshed-3.0.9-cp312-cp312-win_amd64.whl (122 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Using cached srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "Using cached thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "Using cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Using cached marisa_trie-1.2.1-cp312-cp312-win_amd64.whl (150 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 smart-open-7.1.0 spacy-3.8.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 wasabi-1.1.3 weasel-0.4.1\n",
      "Collecting fuzzywuzzy\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.3/12.8 MB ? eta -:--:--\n",
      "     - ------------------------------------- 0.5/12.8 MB 541.6 kB/s eta 0:00:23\n",
      "     - ------------------------------------- 0.5/12.8 MB 541.6 kB/s eta 0:00:23\n",
      "     -- ------------------------------------ 0.8/12.8 MB 599.2 kB/s eta 0:00:21\n",
      "     -- ------------------------------------ 0.8/12.8 MB 599.2 kB/s eta 0:00:21\n",
      "     --- ----------------------------------- 1.0/12.8 MB 629.1 kB/s eta 0:00:19\n",
      "     --- ----------------------------------- 1.3/12.8 MB 692.1 kB/s eta 0:00:17\n",
      "     ---- ---------------------------------- 1.6/12.8 MB 777.0 kB/s eta 0:00:15\n",
      "     ------ -------------------------------- 2.1/12.8 MB 896.4 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.4/12.8 MB 945.5 kB/s eta 0:00:12\n",
      "     ------- ------------------------------- 2.6/12.8 MB 980.6 kB/s eta 0:00:11\n",
      "     --------- ------------------------------ 2.9/12.8 MB 1.0 MB/s eta 0:00:10\n",
      "     --------- ------------------------------ 3.1/12.8 MB 1.0 MB/s eta 0:00:10\n",
      "     ---------- ----------------------------- 3.4/12.8 MB 1.1 MB/s eta 0:00:09\n",
      "     ------------ --------------------------- 3.9/12.8 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.2/12.8 MB 1.1 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 4.5/12.8 MB 1.2 MB/s eta 0:00:08\n",
      "     -------------- ------------------------- 4.7/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 5.0/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 1.2 MB/s eta 0:00:07\n",
      "     ------------------ --------------------- 5.8/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 6.0/12.8 MB 1.2 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 6.6/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     --------------------- ------------------ 6.8/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 1.3 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 7.9/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 8.1/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 8.4/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.7/12.8 MB 1.3 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 8.9/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------ --------- 9.7/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.0/12.8 MB 1.3 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 10.2/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 10.5/12.8 MB 1.3 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 11.5/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.3 MB/s eta 0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting python-Levenshtein\n",
      "  Using cached python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
      "  Using cached levenshtein-0.27.1-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.13.0)\n",
      "Using cached python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
      "Using cached levenshtein-0.27.1-cp312-cp312-win_amd64.whl (100 kB)\n",
      "Installing collected packages: Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.27.1 python-Levenshtein-0.27.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain_google_genai\n",
    "# !pip install langchain_community\n",
    "# !pip install langchain_huggingface\n",
    "# !pip install gradio\n",
    "# !pip install rapidfuzz\n",
    "# !pip install pypdf\n",
    "# !pip install faiss-cpu\n",
    "# !pip install spacy\n",
    "# !pip install fuzzywuzzy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting psycopg2\n",
      "  Using cached psycopg2-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Using cached psycopg2-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Installing collected packages: psycopg2\n",
      "Successfully installed psycopg2-2.9.10\n"
     ]
    }
   ],
   "source": [
    "# !pip install django\n",
    "# !pip install django-cors-headers\n",
    "# !pip install djangorestframework\n",
    "# !pip install drf_spectacular\n",
    "# !pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369208d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\a1mme\\onedrive\\desktop\\mo\\test_grad\\.venv\\lib\\site-packages (25.0.1)\n"
     ]
    }
   ],
   "source": [
    "# !python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8afbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MO\\Depi\\envai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\MO\\Depi\\envai\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "import re, ast\n",
    "import gradio as gr\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import spacy\n",
    "from rapidfuzz import fuzz\n",
    "pdf_file = r\"C:\\Users\\a1mme\\OneDrive\\Desktop\\MO\\test_grad\\chatbot\\res\\Cli script guidebook.pdf\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b9b56",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a640a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm(model_name=\"gemini-1.5-pro\"):\n",
    "    return ChatGoogleGenerativeAI(\n",
    "        model=model_name,\n",
    "        temperature=0.1,\n",
    "        max_output_tokens=500,\n",
    "        google_api_key=\"AIz...\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ff185",
   "metadata": {},
   "source": [
    "Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56dac30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(pdf_file)\n",
    "pdf_docs = loader.load_and_split()\n",
    "\n",
    "# Load mapping\n",
    "with open(\"res/mapping.json\", \"r\") as f:\n",
    "    raw_mapping = json.load(f)\n",
    "\n",
    "with open(\"res/data_mapping.json\", \"r\") as f:\n",
    "    data_mapping = json.load(f)\n",
    "\n",
    "# Format mapping as Document\n",
    "mapping_text = \"\\n\".join(f\"{k} -> {v}\" for k, v in raw_mapping.items())\n",
    "mapping_doc = Document(page_content=mapping_text)\n",
    "\n",
    "all_docs = pdf_docs + [mapping_doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42781df",
   "metadata": {},
   "source": [
    "### Create Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61295ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.from_documents(documents=all_docs, embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19f4b3",
   "metadata": {},
   "source": [
    "### RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c692a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def combine_inputs(input_dict):\n",
    "    question = input_dict[\"question\"]\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "    return {\n",
    "        \"context\": format_docs(retrieved_docs),\n",
    "        \"question\": question\n",
    "    }\n",
    "\n",
    "template = \"\"\"You are an expert assistant trained to extract exact command-line instructions from a user guide.\n",
    "\n",
    "You are also provided with a node-to-subcommand mapping reference (e.g., \"logistic_regression\"  \"model\", \"standard_scaler\"  \"preprocessor\"). Use this mapping only to determine the correct value for <node_name> in the CLI command syntax.\n",
    "\n",
    "Reference Information:\n",
    "{context}\n",
    "\n",
    "User Query:\n",
    "{question}\n",
    "\n",
    "Instructions:\n",
    "- Carefully read the Reference Information, including any node-to-subcommand mappings and CLI usage documentation.\n",
    "- Return the CLI command(s) that are relevant to the user's query with the node name in the node-to subcommand mapping.\n",
    "- Use the mapping to replace <node_name> with its corresponding type (e.g., model, preprocessor, etc.)\n",
    "- IMPORTANT: Never modify or replace <args>. Keep <args> exactly as it is shown.\n",
    "- Format your response as a raw Python list: ['command1', 'command2', ...]\n",
    "- Do NOT include any explanations, comments, or formatting outside the list.\n",
    "- If no command matches the query, return an empty list: []\n",
    "- The output MUST be ordered in the same order as the input.\n",
    "\n",
    "Example Query:\n",
    "I want to make a logistic regression model.\n",
    "\n",
    "Expected Response:\n",
    "[\n",
    "    ('make model <args>', 'logistic_regression')\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough()\n",
    "    | combine_inputs\n",
    "    | prompt\n",
    "    | get_llm(model_name=\"gemini-2.0-flash\")\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177048a",
   "metadata": {},
   "source": [
    "### Keyword Extraction (Hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daee2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_extractor = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "REFERENCE_KEYWORDS = list(raw_mapping.keys())\n",
    "keyword_embeddings = name_extractor.encode(REFERENCE_KEYWORDS, convert_to_tensor=True)\n",
    "\n",
    "def extract_keywords_hybrid(user_input, transformer_thresh=0.7, fuzzy_thresh=80):\n",
    "    doc = nlp(user_input.lower())\n",
    "    phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "    matched_keywords = []\n",
    "\n",
    "    for phrase in phrases:\n",
    "        phrase_embedding = name_extractor.encode(phrase, convert_to_tensor=True)\n",
    "        cosine_scores = util.cos_sim(phrase_embedding, keyword_embeddings)[0]\n",
    "\n",
    "        for idx, score in enumerate(cosine_scores):\n",
    "            if score >= transformer_thresh:\n",
    "                if REFERENCE_KEYWORDS[idx] not in matched_keywords:\n",
    "                    matched_keywords.append(REFERENCE_KEYWORDS[idx])\n",
    "\n",
    "        for keyword in REFERENCE_KEYWORDS:\n",
    "            if fuzz.ratio(phrase, keyword.replace(\"_\", \" \")) >= fuzzy_thresh:\n",
    "                if keyword not in matched_keywords:\n",
    "                    matched_keywords.append(keyword)\n",
    "\n",
    "    return matched_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef6191",
   "metadata": {},
   "source": [
    "### Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d4dd0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_command_list(output: str):\n",
    "    pattern = r\"\\[(.*?)\\]\"\n",
    "    matches = re.findall(pattern, output, re.DOTALL)\n",
    "\n",
    "    if matches:\n",
    "        output = f\"[{matches[0]}]\"\n",
    "\n",
    "    try:\n",
    "        command_list = ast.literal_eval(output.strip())\n",
    "        return command_list if isinstance(command_list, list) else [command_list]\n",
    "    except Exception as e:\n",
    "        return [f\"Failed to parse: {e}\"]\n",
    "\n",
    "def args_extractor(names, mapping, data_mapping):\n",
    "    result = []\n",
    "    for name in names:\n",
    "        if name in mapping and name in data_mapping:\n",
    "            node_type = mapping[name]\n",
    "            args_str = json.dumps(data_mapping[name], separators=(',', ':'))\n",
    "            result.append((node_type, args_str))\n",
    "    return result\n",
    "\n",
    "def replace_args(commands, replacements):\n",
    "    for i in range(len(commands)):\n",
    "        commands[i] = commands[i].replace(\"<node_name>\", replacements[i][0]).replace(\"<args>\", replacements[i][1])\n",
    "    return commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da417c8",
   "metadata": {},
   "source": [
    "### Run Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9592497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make preprocessor {\"preprocessor_name\":\"standard_scaler\",\"preprocessor_type\":\"scaler\",\"params\":{\"with_mean\":true,\"with_std\":true}}',\n",
       " 'make model {\"model_name\":\"linear_regression\",\"task\":\"regression\",\"model_type\":\"linear_models\",\"params\":{}}',\n",
       " 'make model {\"model_name\":\"logistic_regression\",\"task\":\"classification\",\"model_type\":\"linear_models\",\"params\":{\"penalty\":\"l2\",\"C\":1.0}}']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"please add a standard scaler preprocessor, and a linear regressin and logistic regression.\"\n",
    "\n",
    "# RAG output\n",
    "rag_output = rag_chain.invoke({\"question\": question})\n",
    "\n",
    "# Extract command names\n",
    "names = extract_keywords_hybrid(question)\n",
    "\n",
    "# Extract args and types\n",
    "output_list = args_extractor(names, raw_mapping, data_mapping)\n",
    "\n",
    "# Parse RAG and replace placeholders\n",
    "parsed_output = parse_command_list(rag_output)\n",
    "final_output = replace_args(parsed_output, output_list)\n",
    "final_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
